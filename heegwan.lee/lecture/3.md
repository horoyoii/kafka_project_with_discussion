



## Kafka Twitter Producer & Advanced Configurations

1. Twitter Setup

   - Twitter 개발자 계정 등록
     - https://developer.twitter.com/
   - Twitter App 생성

2. Twitter Producer(Write Twitter Client) 실습

   - Java Twitter Client 의존성 추가

     - https://github.com/twitter/hbc : A Java HTTP client for consuming Twitter's standard Streaming API

   - Twitter 실습 순서

     - Twitter Client Build() ***-> https://github.com/twitter/hbd 참고***

     - Twitter Client Connect() to Twitter ***-> https://github.com/twitter/hbd 참고***

     - KafkaProducer를 이용해서 특정 Topic으로 메시지 발행하기 ***-> 기존 KafkaProducer 예제 코드 참고***

     - 결과 확인

       ![image](https://user-images.githubusercontent.com/15210906/119131809-e66fee80-ba74-11eb-95b0-1eee18374136.png)




3. Producers Acks Deep Dive

- acks = 0(no acks)
  - 프로듀서가 메시지를 발행한 후 정상적으로 응답을 안받아도 됨
  - 브로커 서버에 장애가 발생한 경우(메시지를 못받는 상황의 경우), 데이터가 유실될 수 있음
  - 어느 정도 데이터가 유실되도 괜찮다면, 유용한 옵션임
    - Metics 수집
    - Log 수집 ***-> 사용자 Action에 대한 로그이면 어느 정도 유실은 괜찮을 듯***

- acks = 1(leader acks)

  - 프로듀서가 메시지를 발행했을 때, 브로커 리더의 응답을 받아야함

    -> 그러나 follower들의 replication은 보장 못함

    -> follower들로의 복제는 백그라운드에서 진행됨

    -> 응답을 못 받으면 프로듀서는 retry함

  - 복제가 아직 다 되지 않았는데, 리더 브로커가 죽으면 데이터가 유실될 수 있음 

    ***-> 브로커가 다시 살아났을 때 복제를 하면 안되나?***

- acks = all (replicas acks)

  - 프로듀서가 메시지를 발행했을 때, Leader + Replicas ack가 모두 필요함

  - 리더 브로커는 replicas로부터 replication에 대한 결과를 받으면, 프로듀서로 응답을 보냄

  - latency가 생기지만, 데이터 유실이 없어 안전함 
    ![image](https://user-images.githubusercontent.com/15210906/119131894-fc7daf00-ba74-11eb-9e8b-5a8833b3f2c7.png)


  - acks = all 옵션은 min.insync.replicas 옵션과 반드시 같이 사용해야함

  - min.insync.replicas은 브로커 또는 토픽 레벨에서 지정될 수 있다.

  - min.insync.replicas=2 라는 설정은 "데이터를 복제했다. 또는 가지고 있다"라고 응답한 브로커 수가 리더브로커를 포함해 적어도 2여야 된다는 말

  - replication.factor=3, min.insync.replicas=2, acks=all

    -> 이 경우, 한 개의 브로커 장애만 견딜 수 있음. 그 이상으로 브로커에서 장애가 발생하면 프로듀서는 메시지 발행 못함

    -> 최소 2개의 브로커가 데이터를 받았다는 응답이 있어야하기때문에...

4. 프로듀서 Retry

   - 다시 복구가 가능한 장애의 경우, 개발자는 exception 처리가 필요함. 

   - exception 처리를 위해서 retry를 하는데,

     - kafka.version <= 2.0 인 경우, retries=0 임(아예 retry를 하지 않음) 

       ***-> kafka가 자동으로 retry하도록 값을 지정하는게 좋은건가?***

     - kafka.version >= 2.1 인경우, retries=2147483647(매우 높음. 그냥 연결될 때까지 한다고 보면됨.)

   - retry.backoff.ms : 다시 retry하는 간격

   - delivery.timeout.ms : 메시지 발행 timeout 설정 ***-> kafka가 자동으로 retry하도록 값을 지정하는게 좋은건가?의 답변***

   - delivery.timeout.ms 내에 못 받으면 Records는 실패함 ***-> 이것만 처리하면 될듯?***

   - 메시지를 retry하는 경우, 메시지의 순서가 뒤바뀌는 경우가 있을 수 있음

     - Key-based ordering을 할 경우, 이슈가 될 수 있음 ***-> key-based ordering이란 무엇인가....***

     - max.in.flight.requests.per.connection : 병렬로 request를 처리하는 수를 조절
     - 위의 옵션을 1로 설정하면 순서를 보장할 수 있음(디폴트 값은 5) ***-> 성능에 영향을 미친다~***
     - Idempotent Producer가 이 문제를 해결해줄 수 있다~

5. Idempotent Producer

   - 문제점 : 네트워크 에러로 인해 프로듀서는 중복된 메시지를 보낼 수 있음

   - 이로 인해, Commit이 두 번 발생하는 경우가 발생

     ![image](https://user-images.githubusercontent.com/15210906/119131954-128b6f80-ba75-11eb-849d-2ce3b2781544.png)


     

   - idempotent producer로 정의하면, Request ID를 기준으로 동일한 메시지는 두번 commit 하지 않음

     ![image](https://user-images.githubusercontent.com/15210906/119132083-377fe280-ba75-11eb-8956-3b5cbbec8766.png)


   

6. Safe producer Summary & Demo

   - Safe한 프로듀서를 만들려면 다음과 같은 옵션을 설정한다.
     ![image](https://user-images.githubusercontent.com/15210906/119132102-3e0e5a00-ba75-11eb-903d-1d5820b99529.png)


   

7. Message Compression

   - 프로듀서는 주로 TEXT 데이터를 만들어냄.

     - 그래서 압축을 적용하면 효과를 많이 볼듯

   - 압축은 Producer level에서만 하면 되고, 브로커나 컨슈머에는 따로 설정 안해도된다.

     ***-> 아마도 Producer에서 설정하면 컨슈머 Client에서 압축여부에 따라 decompression할것같다.***

   - 압축은 메시지의 크기가 클수록 더 효율적임

     ***-> 얼마나 보내는지 보다 메시지의 크기가 클수록 더 효과적이다***

   - Compressed Producer Message Batch
     ![image](https://user-images.githubusercontent.com/15210906/119132120-449cd180-ba75-11eb-893d-fe79bd23eb34.png)


   - compressed message batch의 장점

     - 프로듀서의 request의 크기가 작아짐
     - 데이터를 전송하는데 빨라짐(크기가 작아지기 때문에)
     - 성능이 좋아짐
     - 카프카에서 디스크 효율성이 좋아짐

   - 단점(사소함)

     - compression, decompression 하는데 CPU를 좀 더 사용함

   - 메시지 압축 권장 사항

     - 보내는 데이터에 따라 압축 알고리즘을 테스트하고 사용해볼 것
     - Production에서는 거의 사용하는게 좋다!

   

8. Linger.ms & batch.size

   - 기본적으로 카프카는 받자마자 데이터를 보냄

     - 데이터를 보내고 있는 중에도 다음에 보낼 데이터를 Batching 하고 있음 ***-> Smart Batching***

   - 카프카의 Batching 기능은 성능을 향상시키면서 low latency를 유지함

   - 또한, 높은 압축률을 갖고 있음

   - 그럼 어떻게 batching을 컨트롤할까?

     -  Linger.ms 옵션 : 메시지 배치를 보내는 데 전까지 기다리는 시간

       ***-> 배치할 메시지를 모으는 시간***

     - batch.size 옵션 : 메시지 배치의 최대 크기(단위는 Byte)

       ***-> Linger.ms 옵션으로 지정된 시간이 지나기 전에 batch.size로 지정된 사이즈보다 모은 메시지의 크기가 커지면 카프카는 그냥 바로 보냄***

     - 약간의 delay(Linger.ms)를 줌으로써, 성능을 향상시킬 수 있다.

       ***-> 어플리케이션에 맞게 결과를 보면서 옵션값을 조절해야할듯??***
       ![image](https://user-images.githubusercontent.com/15210906/119132137-4d8da300-ba75-11eb-898f-c60d88627783.png)


   - batch.size

     - batch size보다 큰 메시지는 배치되지 않음(크면 압축해서 그냥 보내나?)
     - 배치는 파티션 단위로 배정됨
     - Kafka Producer Metrics로 모니터링 할 수 있음

9. Producer Default Partitioner and how keys are hashed

   - Default Key Hashing Algorithm : murmur2
   - formual : tartgetPartition = Utils.abs(Utils.murmur2(record.key()) % numPartitions);

   

